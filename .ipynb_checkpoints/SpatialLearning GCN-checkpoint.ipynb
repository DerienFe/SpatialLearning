{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        output=torch.zeros(input.shape[0],input.shape[1],self.out_features)\n",
    "        for i in range(input.shape[0]):\n",
    "            support = torch.mm(input[i].double(), self.weight.double())\n",
    "            output[i] = torch.spmm(adj[i], support.double())\n",
    "            if self.bias is not None:\n",
    "                for j in range(input.shape[1]):\n",
    "                    output[i,j]=output[i,j] + self.bias\n",
    "    \n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class ave_pooling(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ave_pooling, self).__init__()\n",
    "\n",
    "    \n",
    "    def forward(self,input,length):\n",
    "        output=torch.zeros([input.shape[0],input.shape[-1]])\n",
    "        for i in range(input.shape[0]):\n",
    "            output[i]=input[i,:int(length[i]),:].mean(0)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test example\n",
    "x = torch.rand(2000, 100, 5)\n",
    "y = torch.mean(torch.mean(x,axis=-1),axis=-1)\n",
    "length=np.random.randint(100,size=(2000,1))\n",
    "length=torch.tensor(length)\n",
    "import numpy as np\n",
    "adj=np.zeros([2000,100,100])\n",
    "for i in range(2000):\n",
    "    N = 100\n",
    "    b = np.random.rand(N,N)\n",
    "    b_symm = (b + b.T)/2\n",
    "    adj[i][np.where(b_symm>0.5)]=1\n",
    "adj=torch.tensor(adj)\n",
    "train_x=x[:1500]\n",
    "train_adj=adj[:1500]\n",
    "train_y=y[:1500]\n",
    "train_length=length[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.load('original_features.npy')\n",
    "adj=np.load('adj.npy')\n",
    "length=np.load('length.npy')\n",
    "activity=np.load('activity.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(activity,bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(adj.shape[0]):\n",
    "    adj[i][:length[i],:length[i]]=adj[i][:length[i],:length[i]]+np.eye(length[i])\n",
    "    adj[i]=normalize(adj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=torch.tensor(features)\n",
    "adj=torch.tensor(adj)\n",
    "length=torch.tensor(length)\n",
    "train_x=features[:500]\n",
    "train_adj=adj[:500]\n",
    "train_length=length[:500]\n",
    "valid_x=features[500:600]\n",
    "valid_adj=adj[500:600]\n",
    "valid_length=length[500:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "activity=activity.reshape([activity.shape[0],1])\n",
    "train_activity=activity[:500]\n",
    "valid_activity=activity[500:600]\n",
    "scaler = preprocessing.StandardScaler().fit(train_activity)\n",
    "train_y = scaler.transform(train_activity)\n",
    "valid_y=scaler.transform(valid_activity)\n",
    "train_y=torch.tensor(train_y)\n",
    "valid_y=torch.tensor(valid_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1394, 146])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid1,nhid2,dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid1)\n",
    "        self.gc2 = GraphConvolution(nhid1,nhid2 )\n",
    "        self.ave_pooling=ave_pooling()\n",
    "        self.dropout = dropout\n",
    "        self.linear=torch.nn.Linear(nhid2,1)\n",
    "\n",
    "    def forward(self, x, adj,length):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "        #print(x[0,:,0])\n",
    "        #print(x[0,:int(length[0]),0].mean())\n",
    "        x=self.ave_pooling(x,length)\n",
    "        x=self.linear(x)\n",
    "        #print(y)\n",
    "        #x=self.linear(y)\n",
    "        #print(x)\n",
    "        #print(x)\n",
    "        #\n",
    "        #\n",
    "        #y=self.ave_pooling(x,length)\n",
    "       # y=torch.zeros(x.shape[0],x.shape[-1])\n",
    "        #for i in range(x.shape[0]):\n",
    "          #  y[i]=x[i,:int(length[i]),:].mean(0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN = GCN(nfeat = 146, nhid1=100,nhid2=50,dropout=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gc1): GraphConvolution (146 -> 100)\n",
      "  (gc2): GraphConvolution (100 -> 50)\n",
      "  (ave_pooling): ave_pooling\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "torch_dataset = Data.TensorDataset(train_x,train_adj,train_length, train_y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=1,      # mini batch size\n",
    "    shuffle=True,                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss:  9.771044 valid_loss: 12.7822\n",
      "590.6756973266602\n",
      "1\n",
      "loss:  19.945347 valid_loss: 19.508463\n",
      "1244.0213131904602\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5111e0e4a84c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#print('step:',step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_adj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(prediction,batch_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bdf9d58574ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj, length)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(x[0,:,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(x[0,:int(length[0]),0].mean())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-aa05a82a0a4e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, adj)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "optimizer = torch.optim.Adam(GCN.parameters(), lr=0.001)  \n",
    "loss_func = torch.nn.MSELoss()     \n",
    "\n",
    "start = time.time()\n",
    "hist_train_loss = []\n",
    "hist_valid_loss=[]\n",
    "for t in range(20):\n",
    "    print(t)\n",
    "    for step, (batch_x,batch_adj,batch_length, batch_y) in enumerate(loader):\n",
    "        #print('step:',step)\n",
    "        prediction = GCN(batch_x,batch_adj,batch_length)\n",
    "        #print(prediction,batch_y)\n",
    "        loss = loss_func(prediction, batch_y.float())    \n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "        loss.backward()         \n",
    "        optimizer.step()\n",
    "    prediction_train=GCN(train_x,train_adj,train_length)\n",
    "    loss_train=loss_func(prediction_train, train_y.float()) \n",
    "    prediction_valid = GCN(valid_x,valid_adj,valid_length)\n",
    "    loss_valid = loss_func(prediction_valid, valid_y.float())   \n",
    "    hist_train_loss.append(loss_train.data.cpu().numpy())\n",
    "    hist_valid_loss.append(loss_valid.data.cpu().numpy())\n",
    "    print('loss: ',loss_train.data.cpu().numpy(),'valid_loss:', loss_valid.data.cpu().numpy())\n",
    "    print(time.time()-start)\n",
    "torch.synchronize()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.8386e+00],\n",
       "        [-2.2275e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2791e-01],\n",
       "        [-3.9180e-02],\n",
       "        [-1.3388e-01],\n",
       "        [-2.2778e-01],\n",
       "        [ 3.1223e+00],\n",
       "        [-2.2683e-01],\n",
       "        [-2.1401e-01],\n",
       "        [-2.2741e-01],\n",
       "        [-1.1785e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2731e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-1.7759e-01],\n",
       "        [-2.2581e-01],\n",
       "        [-2.0381e-01],\n",
       "        [-1.7394e-01],\n",
       "        [-2.2858e-01],\n",
       "        [ 9.0956e+00],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2202e-01],\n",
       "        [-2.2732e-01],\n",
       "        [-1.9944e-01],\n",
       "        [ 1.3711e-01],\n",
       "        [-2.2013e-01],\n",
       "        [-2.0818e-01],\n",
       "        [ 1.2210e+00],\n",
       "        [ 2.8309e+00],\n",
       "        [-2.2857e-01],\n",
       "        [ 5.4358e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.0978e-01],\n",
       "        [-2.2811e-01],\n",
       "        [-2.2814e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-3.6266e-02],\n",
       "        [-2.2712e-01],\n",
       "        [-1.9944e-01],\n",
       "        [-2.2760e-01],\n",
       "        [-2.2447e-01],\n",
       "        [ 9.6784e+00],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2848e-01],\n",
       "        [-2.2788e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.0090e-01],\n",
       "        [-2.2764e-01],\n",
       "        [-2.2845e-01],\n",
       "        [ 1.9393e-01],\n",
       "        [-2.2798e-01],\n",
       "        [-2.2713e-01],\n",
       "        [-4.6464e-02],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-9.3668e-02],\n",
       "        [-2.2275e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2721e-01],\n",
       "        [-2.0527e-01],\n",
       "        [-2.2795e-01],\n",
       "        [ 1.1263e+00],\n",
       "        [-2.2801e-01],\n",
       "        [-2.2820e-01],\n",
       "        [-1.0042e-02],\n",
       "        [-1.2674e-01],\n",
       "        [-2.2821e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2654e-01],\n",
       "        [ 4.7249e+00],\n",
       "        [-2.2377e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2304e-01],\n",
       "        [-2.2718e-01],\n",
       "        [-2.2817e-01],\n",
       "        [-2.2779e-01],\n",
       "        [-2.2842e-01],\n",
       "        [-2.2412e-01],\n",
       "        [-4.6464e-02],\n",
       "        [-2.2606e-01],\n",
       "        [-1.9623e-01],\n",
       "        [-2.1984e-01],\n",
       "        [-1.9944e-01],\n",
       "        [ 9.2238e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2857e-01],\n",
       "        [ 2.6677e-01],\n",
       "        [-2.4611e-02],\n",
       "        [ 4.1421e+00],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2842e-01],\n",
       "        [ 4.5275e-03],\n",
       "        [-2.2377e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2785e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2362e-01],\n",
       "        [-1.7016e-01],\n",
       "        [-2.2799e-01],\n",
       "        [-2.2845e-01],\n",
       "        [-2.1415e-01],\n",
       "        [-2.2834e-01],\n",
       "        [ 9.1942e-02],\n",
       "        [-2.2826e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2027e-01],\n",
       "        [-2.2828e-01],\n",
       "        [-1.4408e-01],\n",
       "        [-2.2817e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2566e-01],\n",
       "        [-2.2836e-01],\n",
       "        [-2.2392e-01],\n",
       "        [-2.1692e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.1736e-01],\n",
       "        [-2.2840e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.0643e-01],\n",
       "        [ 4.5275e-03],\n",
       "        [-2.2785e-01],\n",
       "        [ 9.1942e-02],\n",
       "        [-2.2848e-01],\n",
       "        [-2.2827e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2858e-01],\n",
       "        [ 1.3740e+00],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2173e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2839e-01],\n",
       "        [-2.2830e-01],\n",
       "        [-2.2858e-01],\n",
       "        [ 1.3740e+00],\n",
       "        [-2.2828e-01],\n",
       "        [-1.8050e-01],\n",
       "        [ 1.3565e-01],\n",
       "        [-2.2421e-01],\n",
       "        [-2.2654e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-1.9944e-01],\n",
       "        [-2.2115e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2848e-01],\n",
       "        [-1.8783e-02],\n",
       "        [-2.2843e-01],\n",
       "        [-5.8119e-02],\n",
       "        [-2.2858e-01],\n",
       "        [-2.1401e-01],\n",
       "        [-1.6739e-01],\n",
       "        [-2.2845e-01],\n",
       "        [-2.2818e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2847e-01],\n",
       "        [-2.2753e-01],\n",
       "        [-2.1750e-01],\n",
       "        [ 1.0355e-02],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-1.8283e-01],\n",
       "        [-2.2814e-01],\n",
       "        [-2.0978e-01],\n",
       "        [-2.2857e-01],\n",
       "        [ 2.3939e+00],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2817e-01],\n",
       "        [ 3.5418e-01],\n",
       "        [-2.2435e-01],\n",
       "        [ 2.6852e+00],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2649e-01],\n",
       "        [-2.2849e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-1.4871e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2781e-01],\n",
       "        [-2.2848e-01],\n",
       "        [-1.8050e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-1.4699e-01],\n",
       "        [-2.2144e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2795e-01],\n",
       "        [-8.2887e-02],\n",
       "        [-8.2887e-02],\n",
       "        [-2.2836e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2493e-01],\n",
       "        [-1.8633e-01],\n",
       "        [-2.2673e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2819e-01],\n",
       "        [-2.2804e-01],\n",
       "        [-2.1372e-01],\n",
       "        [-2.2814e-01],\n",
       "        [-2.2827e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2514e-01],\n",
       "        [ 1.5197e+00],\n",
       "        [-2.2781e-01],\n",
       "        [-2.2595e-01],\n",
       "        [-2.2604e-01],\n",
       "        [-2.2838e-01],\n",
       "        [-2.2284e-01],\n",
       "        [-2.2816e-01],\n",
       "        [-2.2566e-01],\n",
       "        [-1.7176e-01],\n",
       "        [-2.2464e-01],\n",
       "        [ 4.2703e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2792e-01],\n",
       "        [-1.1202e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.0731e-01],\n",
       "        [-2.2852e-01],\n",
       "        [ 1.4726e-02],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2785e-01],\n",
       "        [-1.7205e-01],\n",
       "        [ 1.2866e+00],\n",
       "        [-2.2848e-01],\n",
       "        [-4.5007e-02],\n",
       "        [ 1.6610e+00],\n",
       "        [ 4.4160e-01],\n",
       "        [-2.2713e-01],\n",
       "        [-1.4116e-01],\n",
       "        [-2.2776e-01],\n",
       "        [-2.2842e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2743e-01],\n",
       "        [-2.2849e-01],\n",
       "        [-2.2846e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-1.2368e-01],\n",
       "        [-2.1109e-01],\n",
       "        [-2.2802e-01],\n",
       "        [-2.0818e-01],\n",
       "        [-2.2435e-01],\n",
       "        [-2.1258e-01],\n",
       "        [-2.2833e-01],\n",
       "        [ 2.5220e-01],\n",
       "        [-2.2493e-01],\n",
       "        [-2.2708e-01],\n",
       "        [-2.2831e-01],\n",
       "        [-2.0964e-01],\n",
       "        [ 7.7669e-01],\n",
       "        [-1.0042e-02],\n",
       "        [-2.2837e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2848e-01],\n",
       "        [-2.2855e-01],\n",
       "        [ 1.2283e+00],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.0905e-01],\n",
       "        [-1.5865e-01],\n",
       "        [ 7.3298e-01],\n",
       "        [ 7.8106e-01],\n",
       "        [-2.2846e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2839e-01],\n",
       "        [-2.2507e-01],\n",
       "        [-2.2849e-01],\n",
       "        [-2.1471e-01],\n",
       "        [ 1.9568e+00],\n",
       "        [-2.2493e-01],\n",
       "        [-2.2838e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2795e-01],\n",
       "        [-2.2566e-01],\n",
       "        [-1.6593e-01],\n",
       "        [-4.6464e-02],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2811e-01],\n",
       "        [-1.4990e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.0308e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2779e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2830e-01],\n",
       "        [-2.1984e-01],\n",
       "        [-2.2435e-01],\n",
       "        [-2.2844e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2817e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2027e-01],\n",
       "        [-2.2275e-01],\n",
       "        [-2.2595e-01],\n",
       "        [-2.2730e-01],\n",
       "        [-2.1270e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2816e-01],\n",
       "        [-2.2595e-01],\n",
       "        [-1.9769e-01],\n",
       "        [-2.2697e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2740e-01],\n",
       "        [-2.1663e-01],\n",
       "        [-2.2854e-01],\n",
       "        [ 1.3565e-01],\n",
       "        [-2.2844e-01],\n",
       "        [ 6.7470e-01],\n",
       "        [-1.8341e-01],\n",
       "        [-2.2770e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2252e-01],\n",
       "        [-1.9801e-01],\n",
       "        [-2.2855e-01],\n",
       "        [ 7.6387e+00],\n",
       "        [-2.2091e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2639e-01],\n",
       "        [ 1.1234e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2625e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2824e-01],\n",
       "        [-2.2654e-01],\n",
       "        [-2.2781e-01],\n",
       "        [-2.2855e-01],\n",
       "        [ 1.2866e+00],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2581e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2683e-01],\n",
       "        [-2.2837e-01],\n",
       "        [-2.2748e-01],\n",
       "        [-2.2837e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2610e-01],\n",
       "        [-2.2846e-01],\n",
       "        [-2.2807e-01],\n",
       "        [-1.4553e-01],\n",
       "        [-2.2524e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2838e-01],\n",
       "        [-2.2815e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2813e-01],\n",
       "        [-2.2851e-01],\n",
       "        [ 2.5220e-01],\n",
       "        [-1.9871e-01],\n",
       "        [-2.2836e-01],\n",
       "        [-2.2785e-01],\n",
       "        [-2.0381e-01],\n",
       "        [-1.8895e-01],\n",
       "        [-2.6067e-02],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2846e-01],\n",
       "        [-2.2639e-01],\n",
       "        [-2.2760e-01],\n",
       "        [-1.1931e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2115e-01],\n",
       "        [ 1.3740e+00],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.0905e-01],\n",
       "        [ 3.8624e-01],\n",
       "        [-2.2804e-01],\n",
       "        [-2.2845e-01],\n",
       "        [-2.1488e-01],\n",
       "        [-1.9507e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2683e-01],\n",
       "        [-2.2830e-01],\n",
       "        [-2.0964e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-1.1202e-01],\n",
       "        [-2.2751e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2697e-01],\n",
       "        [-2.1754e-01],\n",
       "        [-2.2664e-01],\n",
       "        [-2.2846e-01],\n",
       "        [-2.1882e-01],\n",
       "        [ 2.3239e+00],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2806e-01],\n",
       "        [-1.1494e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2517e-01],\n",
       "        [-1.1202e-01],\n",
       "        [-2.2764e-01],\n",
       "        [-2.2856e-01],\n",
       "        [ 4.9987e-01],\n",
       "        [-2.2850e-01],\n",
       "        [-2.2814e-01],\n",
       "        [-2.2712e-01],\n",
       "        [-2.2228e-01],\n",
       "        [ 1.6654e+00],\n",
       "        [-2.2013e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2811e-01],\n",
       "        [-1.9798e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2403e-01],\n",
       "        [-2.2762e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.8981e-02],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2849e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2787e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2799e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2823e-01],\n",
       "        [-2.1619e-01],\n",
       "        [-2.2683e-01],\n",
       "        [-2.2856e-01],\n",
       "        [ 4.4160e-01],\n",
       "        [-2.2188e-01],\n",
       "        [-2.2683e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-1.9507e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2836e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-1.6302e-01],\n",
       "        [-2.2813e-01],\n",
       "        [-2.2619e-01],\n",
       "        [-2.2858e-01],\n",
       "        [-2.2847e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2840e-01],\n",
       "        [-2.2791e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2814e-01],\n",
       "        [-2.2853e-01],\n",
       "        [-2.2840e-01],\n",
       "        [-2.2406e-01],\n",
       "        [-2.2851e-01],\n",
       "        [ 1.9568e+00],\n",
       "        [-2.2855e-01],\n",
       "        [-2.1852e-01],\n",
       "        [-2.2848e-01],\n",
       "        [-2.2719e-01],\n",
       "        [ 8.3496e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2849e-01],\n",
       "        [-2.2499e-01],\n",
       "        [ 6.0361e+00],\n",
       "        [ 6.5717e-02],\n",
       "        [-2.2856e-01],\n",
       "        [-2.0818e-01],\n",
       "        [-2.2759e-01],\n",
       "        [-2.2595e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2756e-01],\n",
       "        [-2.2857e-01],\n",
       "        [-2.2857e-01],\n",
       "        [ 9.3695e-01],\n",
       "        [ 4.5617e-01],\n",
       "        [-2.2702e-01],\n",
       "        [ 3.9789e-01],\n",
       "        [-2.2851e-01],\n",
       "        [-2.2290e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-1.8487e-01],\n",
       "        [-2.2852e-01],\n",
       "        [-2.2855e-01],\n",
       "        [-2.2842e-01],\n",
       "        [-2.2854e-01],\n",
       "        [-2.2856e-01],\n",
       "        [-2.2857e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
